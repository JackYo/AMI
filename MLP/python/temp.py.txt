import csv
import sys
import warnings

import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_boston
from sklearn.neural_network import MLPRegressor
from sklearn.utils.testing import (assert_raises, assert_greater, assert_equal,
								   assert_false, ignore_warnings)

n_features = None

def readcsv(data_file_name, answer_file_name):
	global n_features
	with open(data_file_name) as f:
		data_file = csv.reader(f)
		temp = next(data_file)
		n_samples = int(temp[0])-1
		n_features = int(temp[1])
		#date = np.empty((n_samples,), dtype=np.object)
		
		#reader = csv.reader(open("test.csv", "rb"), delimiter=",")
			
		# names of features
		temp = next(data_file)  
		feature_names = np.array(temp)
		
		# date and feature data
		x = list(data_file)
		data = numpy.array(x).astype("float")
		first_time = data[0][0].
		# data on time
		data_on_time = np.empty((24, n_samples, n_features))
		for i in range(0,24,1):
			data_on_time[i] = data[i:n_samples-1:24][1:]
		
		
		"""
		for i, d in enumerate(data_file):
			if i < n_samples-1:
				#parse out time flag
				#time[0] = "00:00", time[1] = "01:00", ...
				
				date[i] = d[0]
				data[i] = np.asarray(d[1:], dtype=np.float64)
				#target[i] = np.asarray(d[-1], dtype=np.float64)
		"""
		
		target = np.empty((n_samples,))
		with open(answer_file_name) as f2:
			answer_file = csv.reader(f2)
			for j, e in enumerate(answer_file):
				target[j] = np.asarray(e[0], dtype=np.float64)

		return data, target, date


def predict_user():
	sampleMin = 0
	sampleMax = 100
	#predictMin = 100
	#predictMax = 150
	featureIndex = sampleMax
	targetIndex = sampleMin
	#testTargetIndexL = predictMin
	#testTargetIndexR = predictMax


	date_predict = np.empty((1,5), dtype=np.object)
	date_predict_array = np.empty((0,5))

def predict_complete():
	sampleMin = 0
	sampleMax = 100
	predictMin = 100
	predictMax = 150
	featureIndex = sampleMax
	targetIndex = sampleMin
	testTargetIndexL = predictMin
	testTargetIndexR = predictMax


	date_predict = np.empty((1,5), dtype=np.object)
	date_predict_array = np.empty((0,5))

	for k in range(1,97):

		X = Xbos[sampleMin:featureIndex]
		y = combinedData[1][targetIndex:sampleMax]


		Xtest = Xbos[predictMin:predictMax]
		ytest = combinedData[1][testTargetIndexL:testTargetIndexR]

		#Xpredict = Xbos[predictMin].reshape(1,-1)
		
		Xpredict = np.empty((n_features,))
		for j in range(1,n_features):
			Xpredict[j-1] = float(sys.argv[j])
		Xpredict = Xpredict.reshape(1,-1)
		
		#ypredict = combinedData[1][testTargetIndexL].reshape(1,-1)

		# use logistic
		mlp = MLPRegressor(solver='lbfgs', hidden_layer_sizes=50,max_iter=150, warm_start=True, shuffle=True, random_state=1,activation="logistic") 
		mlp.fit(X, y)
		
		"""
		if activation == 'identity':
			assert_greater(mlp.score(X, y), 0.84)
		else:
			# Non linear models perform much better than linear bottleneck:
			assert_greater(mlp.score(X, y), 0.95)
			"""

		#show training parameter
		print('ACTIVATION_TYPES - {0} : '.format("logistic"))

		#show training score
		trainingScore = mlp.score(X,y)
		date_predict[0][3]= trainingScore
		print('training score is {0}'.format(trainingScore))
		
		#calculate predict score
		predictScore = mlp.score(Xtest, ytest)
		date_predict[0][4]= predictScore
		print('predict score is {0}'.format(predictScore))

		#real predict
		predict = mlp.predict(Xpredict)

		date_predict[0][0]= k
		date_predict[0][1]= predict[0]
		date_predict[0][2]= combinedData[0][testTargetIndexL+1][n_features-1]
		print('predict result:\n {0}'.format(predict))

		featureIndex = featureIndex-1
		targetIndex = targetIndex+1
		testTargetIndexL = testTargetIndexL+1
		testTargetIndexR = testTargetIndexR+1
		date_predict_array= np.append(date_predict_array,date_predict,0)

		print('\n')

	print("next_n_time", "prediction", "origin", "training score", "predicting score")
	print(date_predict_array)
	with open('../output/output_complete.csv', 'w') as csvfile:
		#spamwriter = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)
		spamwriter = csv.writer(csvfile, delimiter=',')
		spamwriter.writerow(["next_n_time", "prediction", "origin", "training_score", "predicting_score"])
		
		for row in date_predict_array:
			spamwriter.writerow(row)

ACTIVATION_TYPES = ["identity", "logistic", "tanh", "relu"]

combinedData = readcsv('../data/rawData.csv','../data/answerData.csv')
#combinedData = load_boston()

Xbos = StandardScaler().fit_transform(combinedData[0])

date = combinedData[2]


predict_complete()